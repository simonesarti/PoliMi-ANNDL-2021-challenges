{"nbformat":4,"nbformat_minor":0,"metadata":{"interpreter":{"hash":"79864fec6e86ef6f7677947f73bd751147020c6ec100aa24f3fb0cd9010be83c"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('APIs': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"colab":{"name":"Best_EfficientNet_laurav2.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T21:20:07.517065Z","iopub.status.busy":"2021-11-19T21:20:07.516824Z","iopub.status.idle":"2021-11-19T21:20:22.698847Z","shell.execute_reply":"2021-11-19T21:20:22.697342Z","shell.execute_reply.started":"2021-11-19T21:20:07.516998Z"},"trusted":true,"id":"kjxfZI0wip5g","outputId":"940abb77-7819-4631-9492-c09b8eb462cb"},"source":["#Here we import the libraries needed\n","import tensorflow as tf\n","import numpy as np\n","import os\n","import random\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.metrics import confusion_matrix\n","\n","from PIL import Image\n","\n","!pip install visualkeras\n","import visualkeras #to draw the CNNs\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)"],"execution_count":null,"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10020/3826876764.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"]}]},{"cell_type":"markdown","metadata":{"id":"HJPrivboip5w"},"source":["## set seed for reproducibility\n"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:46:44.47447Z","iopub.status.busy":"2021-11-19T12:46:44.4742Z","iopub.status.idle":"2021-11-19T12:46:44.489047Z","shell.execute_reply":"2021-11-19T12:46:44.488238Z","shell.execute_reply.started":"2021-11-19T12:46:44.474437Z"},"trusted":true,"id":"fEm62mhQip50"},"source":["# setting the Random seed for reproducibility of the experiments\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KQB-k537ip53"},"source":["## Get and split the dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:46:44.494053Z","iopub.status.busy":"2021-11-19T12:46:44.49346Z","iopub.status.idle":"2021-11-19T12:46:51.99389Z","shell.execute_reply":"2021-11-19T12:46:51.993006Z","shell.execute_reply.started":"2021-11-19T12:46:44.494019Z"},"trusted":true,"id":"6jl4NLx9ip55"},"source":["!pip install split-folders \n","import splitfolders"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:46:51.999011Z","iopub.status.busy":"2021-11-19T12:46:51.998779Z","iopub.status.idle":"2021-11-19T12:47:46.233228Z","shell.execute_reply":"2021-11-19T12:47:46.232511Z","shell.execute_reply.started":"2021-11-19T12:46:51.998983Z"},"trusted":true,"id":"zgBwGkDqip57"},"source":["#splitfolder allows to split the content of a directory passed as argument, and creates another output folder which contains three directories\n","#called \"train\",\"val\",\"test\" containing each a specified fraction of the elements in the input folder (Splitfolders preserves the ratio for each class\n","#of element present in the input directory) \n","training_ratio=0.8    \n","validation_ratio=0.15     \n","testing_ratio=0.05    \n","splitfolders.ratio('/kaggle/input/dataset/training', output='partitioned_dataset', seed = seed, ratio=(training_ratio,validation_ratio,testing_ratio))\n","#https://pypi.org/project/split-folders/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:46.235015Z","iopub.status.busy":"2021-11-19T12:47:46.234601Z","iopub.status.idle":"2021-11-19T12:47:46.239861Z","shell.execute_reply":"2021-11-19T12:47:46.23901Z","shell.execute_reply.started":"2021-11-19T12:47:46.234977Z"},"trusted":true,"id":"lkDQkMjSip6A"},"source":["# define Dataset folders to be used later\n","dataset_dir = 'partitioned_dataset'\n","training_dir = os.path.join(dataset_dir, 'train')\n","validation_dir = os.path.join(dataset_dir, 'val')\n","test_dir = os.path.join(dataset_dir, 'test')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J4-xpCGqip6B"},"source":["# model parameters"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:46.241703Z","iopub.status.busy":"2021-11-19T12:47:46.241028Z","iopub.status.idle":"2021-11-19T12:47:46.251855Z","shell.execute_reply":"2021-11-19T12:47:46.251086Z","shell.execute_reply.started":"2021-11-19T12:47:46.241665Z"},"trusted":true,"id":"pSZmk2pXip6C"},"source":["#List the labels with which our system will have to deal\n","labels = ['Apple',              # 0\n","          'Blueberry',          # 1\n","          \"Cherry\",             # 2\n","          \"Corn\",               # 3\n","          \"Grape\",              # 4\n","          \"Orange\",             # 5\n","          \"Peach\",              # 6\n","          \"Pepper\",             # 7\n","          \"Potato\",             # 8\n","          \"Raspberry\",          # 9\n","          \"Soybean\",            # 10\n","          \"Squash\",             # 11\n","          \"Strawberry\",         # 12\n","          \"Tomato\"]             # 13\n","\n","#for a total of 14 classes\n","number_of_classes = 14"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:46.255221Z","iopub.status.busy":"2021-11-19T12:47:46.255005Z","iopub.status.idle":"2021-11-19T12:47:46.261742Z","shell.execute_reply":"2021-11-19T12:47:46.261012Z","shell.execute_reply.started":"2021-11-19T12:47:46.255182Z"},"trusted":true,"id":"2Cj1zdIrip6F"},"source":["#dealing with 256x256 rgb (3 channels) images\n","input_shape = (256, 256, 3)\n","image_width = 256\n","image_height = 256\n","\n","\n","epochs = 100 #number of epochs\n","patience_epochs = 30 # number of epochs for early stopping\n","batch_size = 32"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4mMK9Arcip6G"},"source":["# data loader and augmentation"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:49.93399Z","iopub.status.busy":"2021-11-19T12:47:49.932462Z","iopub.status.idle":"2021-11-19T12:47:51.153602Z","shell.execute_reply":"2021-11-19T12:47:51.152878Z","shell.execute_reply.started":"2021-11-19T12:47:49.933946Z"},"trusted":true,"id":"TGS6G7EFip6H"},"source":["# Images are divided into folders, one for each class. \n","# If the images are organized in such a way, we can exploit the ImageDataGenerator to read them from disk.\n","# Needed if the images are too many to be kept in memory\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","#import the preprocessing function needed for the transfer leaning network used below, must use the same preprocessing for the images \n","from tensorflow.keras.applications.efficientnet import preprocess_input \n","\n","#Image data generators can be used for data augmentation\n","# Create an instance of ImageDataGenerator for training, validation, and test sets. Transformations are applied only on training images\n","image_gen_train = ImageDataGenerator(rotation_range=90,         #rotate +/- x degree\n","                                        height_shift_range=50,  # [low, high] pixel shift\n","                                        width_shift_range=50,   # [low, high] pixel shift\n","                                        zoom_range=0.4,         #zoom rate\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        brightness_range=[0.4,1.6], #ranges of brightness modification\n","                                        shear_range=0.2, \n","                                        fill_mode='constant', cval=0.,  #fill pixel outised the image due to shifts and rotations with black pixels\n","                                        preprocessing_function=preprocess_input)    #apply the neural network's preprocessing function\n","                                        \n","                                        \n","#flow from directory takes images from the directory passed, divides them into batched of the specified size and applies the image generator to obtain a\n","#random configuration of the orginal image, the transformations applied depend on the parameter passed to the ImageDataGenerator\n","train_generator = image_gen_train.flow_from_directory(directory=training_dir,\n","                                               target_size=(256,256),#size of images\n","                                               color_mode='rgb',#channels\n","                                               classes=labels, # set to labels of classes, see above\n","                                               class_mode='categorical',\n","                                               batch_size=batch_size, \n","                                               shuffle=True,#data gets shuffled when epoch ends and new one begins\n","                                               seed=seed)\n","\n","\n","\n","# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n","image_gen_val = ImageDataGenerator(preprocessing_function=preprocess_input)\n","                                    \n","valid_generator = image_gen_val.flow_from_directory(directory=validation_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=labels, \n","                                               class_mode='categorical',\n","                                               batch_size=batch_size,\n","                                               shuffle=False,#shuffle irrelevant for validation (and testing)\n","                                               seed=seed)\n","\n","\n","\n","image_gen_test = ImageDataGenerator(preprocessing_function=preprocess_input)\n","                                    \n","test_generator = image_gen_test.flow_from_directory(directory=test_dir,\n","                                              target_size=(256,256),\n","                                              color_mode='rgb',\n","                                              classes=labels,\n","                                              class_mode='categorical',\n","                                              batch_size=batch_size,\n","                                              shuffle=False,\n","                                              seed=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Lq0XpAGip6K"},"source":["# class weighting for generators"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:51.166775Z","iopub.status.busy":"2021-11-19T12:47:51.166253Z","iopub.status.idle":"2021-11-19T12:47:51.180138Z","shell.execute_reply":"2021-11-19T12:47:51.17944Z","shell.execute_reply.started":"2021-11-19T12:47:51.166738Z"},"trusted":true,"id":"MFl9nMrEip6L"},"source":["#used for re-weighting classes considering that the number of samples in the dataset for each class are unbalanced\n","\n","from sklearn.utils import class_weight\n","\n","class_weights = class_weight.compute_class_weight(\n","    class_weight = 'balanced',\n","    classes = np.unique(train_generator.classes),\n","    y = train_generator.classes\n",")\n","train_class_weights = dict(enumerate(class_weights))\n","print(train_class_weights)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZO8myjJip6M"},"source":["# function to create folders and callbacks\n"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:51.183115Z","iopub.status.busy":"2021-11-19T12:47:51.182929Z","iopub.status.idle":"2021-11-19T12:47:51.193196Z","shell.execute_reply":"2021-11-19T12:47:51.192481Z","shell.execute_reply.started":"2021-11-19T12:47:51.183092Z"},"trusted":true,"id":"tpo1FEFXip6M"},"source":["# Utility function to create folders and callbacks for training\n","\n","from datetime import datetime\n","\n","def create_folders_and_callbacks(model_name):\n","\n","  exps_dir = os.path.join('data_augmentation_experiments')#create a folder for experiences\n","  if not os.path.exists(exps_dir):\n","      os.makedirs(exps_dir)\n","\n","  now = datetime.now().strftime('%b%d_%H-%M-%S')#assign different name every time experimenti is run\n","\n","  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","  if not os.path.exists(exp_dir):\n","      os.makedirs(exp_dir)\n","      \n","  callbacks = []\n","\n","  # Model checkpoint\n","  # ----------------\n","  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","  if not os.path.exists(ckpt_dir):\n","      os.makedirs(ckpt_dir)\n","\n","  #CHECKPOINT CALLBACK\n","  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), #where to save model/checkpoints\n","                                                     save_weights_only=False, # True to save only weights, false save all the model\n","                                                     save_best_only=True,# True to save only the best epoch, false save all epochs\n","                                                     monitor='val_accuracy',#monitor the accuracy metric\n","                                                     mode='max')\n","  callbacks.append(ckpt_callback)\n","\n","  # Visualize Learning on Tensorboard\n","  # ---------------------------------\n","  tb_dir = os.path.join(exp_dir, 'tb_logs')\n","  if not os.path.exists(tb_dir):\n","      os.makedirs(tb_dir)\n","      \n"," # By default shows losses and metrics for both training and validation in tensorboard\n","  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n","                                               profile_batch=0,\n","                                               histogram_freq=1)  #epoch frequency, if > 0 (epochs) shows weights histograms\n","  callbacks.append(tb_callback)#append to callback list\n","\n","  # Early Stopping\n","  # --------------\n","  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience_epochs, restore_best_weights=True)\n","  callbacks.append(es_callback)\n","\n","  return callbacks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qKU_Jkt6ip6N"},"source":["# transfer learning with EfficientNetB5"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:51.194812Z","iopub.status.busy":"2021-11-19T12:47:51.194561Z","iopub.status.idle":"2021-11-19T12:47:55.071502Z","shell.execute_reply":"2021-11-19T12:47:55.070797Z","shell.execute_reply.started":"2021-11-19T12:47:51.194778Z"},"trusted":true,"id":"eyFh81o1ip6P"},"source":["# Download and plot the EfficientNet model\n","pre_trained_model = tfk.applications.EfficientNetB5(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_shape=(256,256,3)\n",")\n","\n","#set EfficientNet as non-trainable (transfer learning)\n","pre_trained_model.trainable = False\n","\n","#show and plot the structure of the EfficientNet network    \n","pre_trained_model.summary()\n","visualkeras.layered_view(pre_trained_model, legend=True, spacing=15, scale_xy=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:55.073526Z","iopub.status.busy":"2021-11-19T12:47:55.073263Z","iopub.status.idle":"2021-11-19T12:47:55.210729Z","shell.execute_reply":"2021-11-19T12:47:55.210028Z","shell.execute_reply.started":"2021-11-19T12:47:55.073491Z"},"trusted":true,"id":"eC1jdwOvip6P"},"source":["# Use the supernet as feature extractor\n","input_layer = tfk.Input(shape=input_shape)\n","\n","supernet = pre_trained_model(input_layer) #2048 output\n","\n","#concatenate a fully connected NN to the exit of the pre-trained model\n","glob_pooling = tfkl.GlobalAveragePooling2D()(supernet)\n","batch_norm = tfkl.BatchNormalization()(glob_pooling)\n","\n","classifier1 = tfkl.Dense(512,kernel_initializer = tfk.initializers.GlorotUniform(seed))(batch_norm)\n","classifier1 = tfkl.ELU()(classifier1)#use ELU activation function\n","classifier1 = tfkl.Dropout(0.3, seed=seed)(classifier1)#close to the input layer, use lower dropout rate\n","\n","classifier2 = tfkl.Dense(256,kernel_initializer = tfk.initializers.GlorotUniform(seed))(classifier1)\n","classifier2 = tfkl.ELU()(classifier2)\n","classifier2 = tfkl.Dropout(0.6, seed=seed)(classifier2)#in the middle of the hidden layers, increase droput rate\n","\n","classifier3 = tfkl.Dense(64,kernel_initializer = tfk.initializers.GlorotUniform(seed))(classifier2)\n","classifier3 = tfkl.ELU()(classifier3)\n","\n","output_layer = tfkl.Dense(number_of_classes, activation='softmax',kernel_initializer = tfk.initializers.GlorotUniform(seed))(classifier3)\n","\n","# Connect input and output through the Model class\n","transfer_model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n","\n","# Compile the model\n","transfer_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","transfer_model.summary()\n","visualkeras.layered_view(transfer_model, legend=True, spacing=15, scale_xy=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0iwIofGHip6Q"},"source":["# fine tuning"]},{"cell_type":"code","metadata":{"id":"m2Zsv5UOip6R"},"source":["#set pre-trained model as trainable\n","transfer_model.get_layer('efficientnetb5').trainable=True\n","\n","#freeze up to 292nd level\n","to_freeze=293\n","for layer in transfer_model.get_layer('efficientnetb5').layers[:to_freeze]:\n","      layer.trainable = False\n","\n","#freeze batch_normalization layers\n","for layer in transfer_model.get_layer('efficientnetb5').layers:\n","   if isinstance(layer, tfk.layers.BatchNormalization):\n","      layer.trainable = False\n","\n","#check1\n","print(\"check trainability whole model\")\n","for i, layer in enumerate(transfer_model.layers):\n","    print(i, layer.name, layer.trainable)\n","\n","#check2\n","print(\"\\ncheck trainability of efficientnet model\")\n","for i, layer in enumerate(transfer_model.get_layer('efficientnetb5').layers):\n","    print(i, layer.name, layer.trainable)\n","\n","\n","#compile the model\n","learning_rate=1e-5\n","transfer_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate), metrics='accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D3jMjVuAip6R"},"source":["#https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3GRWNw7Mip6R"},"source":["# fitting and testing"]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T12:47:55.212479Z","iopub.status.busy":"2021-11-19T12:47:55.212032Z","iopub.status.idle":"2021-11-19T15:19:04.149093Z","shell.execute_reply":"2021-11-19T15:19:04.148079Z","shell.execute_reply.started":"2021-11-19T12:47:55.212439Z"},"trusted":true,"id":"_7klaYV-ip6S"},"source":["#transfer model training\n","# tf.get_logger().setLevel('WARNING') #  if you want to suppress only INFOs\n","# tf.get_logger().setLevel('ERROR') #  if you want to suppress both WARNINGs and INFOs\n","\n","# Create folders and callbacks and fit\n","aug_callbacks = create_folders_and_callbacks(model_name='CNN')\n","\n","# Train the model\n","transfer_history = transfer_model.fit(\n","    #pass the training augmeneted set\n","    x = train_generator,\n","    epochs = epochs,\n","    #pass the validation augmeneted set\n","    validation_data = valid_generator,\n","    callbacks = aug_callbacks,\n","    class_weight = train_class_weights\n",").history\n","\n","#save the model\n","transfer_model.save(\"TransferLearningModel\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T15:19:04.152345Z","iopub.status.busy":"2021-11-19T15:19:04.152078Z","iopub.status.idle":"2021-11-19T15:19:04.685461Z","shell.execute_reply":"2021-11-19T15:19:04.684613Z","shell.execute_reply.started":"2021-11-19T15:19:04.152301Z"},"trusted":true,"id":"ue0eO8tWip6S"},"source":["# Plot the training\n","plt.figure(figsize=(15,5))\n","plt.plot(transfer_history['loss'], label='training', alpha=.8, color='#ff7f0e')\n","plt.plot(transfer_history['val_loss'], label='validation', alpha=.8, color='#4D61E2')\n","plt.legend(loc='upper left')\n","plt.title('Categorical Crossentropy')\n","plt.grid(alpha=.3)\n","\n","plt.figure(figsize=(15,5))\n","plt.plot(transfer_history['accuracy'], label='training', alpha=.8, color='#ff7f0e')\n","plt.plot(transfer_history['val_accuracy'], label='transfer', alpha=.8, color='#4D61E2')\n","plt.legend(loc='upper left')\n","plt.title('Accuracy')\n","plt.grid(alpha=.3)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.execute_input":"2021-11-19T15:19:04.68772Z","iopub.status.busy":"2021-11-19T15:19:04.686866Z","iopub.status.idle":"2021-11-19T15:19:18.487872Z","shell.execute_reply":"2021-11-19T15:19:18.486794Z","shell.execute_reply.started":"2021-11-19T15:19:04.68767Z"},"trusted":true,"id":"Eomblf1pip6T"},"source":["#load the model and\n","#evaluate on augmented test set\n","model_transf = tfk.models.load_model(\"TransferLearningModel\")\n","model_transf_test_metrics = model_transf.evaluate(test_generator, return_dict=True)"],"execution_count":null,"outputs":[]}]}