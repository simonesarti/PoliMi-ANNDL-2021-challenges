{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"No Transfer Learning.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"0Q1RQ5TFTcPh"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"id":"__zxlZlXTEf4","execution":{"iopub.status.busy":"2021-11-22T16:32:33.403962Z","iopub.execute_input":"2021-11-22T16:32:33.404288Z","iopub.status.idle":"2021-11-22T16:32:39.122942Z","shell.execute_reply.started":"2021-11-22T16:32:33.404204Z","shell.execute_reply":"2021-11-22T16:32:39.122112Z"},"trusted":true},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import random\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JiPBLEOiPSpb"},"source":["# Setting the random seed"]},{"cell_type":"code","metadata":{"id":"dngnG3pQTKDR","execution":{"iopub.status.busy":"2021-11-22T16:32:41.950473Z","iopub.execute_input":"2021-11-22T16:32:41.951068Z","iopub.status.idle":"2021-11-22T16:32:41.958406Z","shell.execute_reply.started":"2021-11-22T16:32:41.951027Z","shell.execute_reply":"2021-11-22T16:32:41.957495Z"},"trusted":true},"source":["seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-AMtcauWBSv"},"source":["# Dataset configuration \n"]},{"cell_type":"code","metadata":{"id":"Ec1TCv1ky3PY","execution":{"iopub.status.busy":"2021-11-22T16:37:29.844387Z","iopub.execute_input":"2021-11-22T16:37:29.844945Z","iopub.status.idle":"2021-11-22T16:37:39.279241Z","shell.execute_reply.started":"2021-11-22T16:37:29.844906Z","shell.execute_reply":"2021-11-22T16:37:39.278299Z"},"trusted":true},"source":["#additional component to perform the split\n","!pip install split-folders \n","import splitfolders"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DEYoB3O0zIaB","execution":{"iopub.status.busy":"2021-11-22T16:37:41.409073Z","iopub.execute_input":"2021-11-22T16:37:41.410013Z","iopub.status.idle":"2021-11-22T16:39:29.983938Z","shell.execute_reply.started":"2021-11-22T16:37:41.409961Z","shell.execute_reply":"2021-11-22T16:39:29.983154Z"},"trusted":true},"source":["splitfolders.ratio('/kaggle/input/images/training', output='outputDataset', seed = seed, ratio=(0.85, 0.1, 0.05))\n","#in this case we set a path compatible to the kaggle environment, if the program in run on colab we also need to perform an unzip the first time.\n","#85% testing\n","#10 validation\n","#5% testing\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYiWuP2HT1Vb","execution":{"iopub.status.busy":"2021-11-22T16:39:52.64439Z","iopub.execute_input":"2021-11-22T16:39:52.644989Z","iopub.status.idle":"2021-11-22T16:39:52.650204Z","shell.execute_reply.started":"2021-11-22T16:39:52.644947Z","shell.execute_reply":"2021-11-22T16:39:52.64912Z"},"trusted":true},"source":["# Dataset folders are set here\n","dataset_dir = 'outputDataset'\n","training_dir = os.path.join(dataset_dir, 'train')\n","validation_dir = os.path.join(dataset_dir, 'val')\n","test_dir = os.path.join(dataset_dir, 'test')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qsyu_KSr2Dtn"},"source":["# Model Parameters"]},{"cell_type":"code","metadata":{"id":"lvQFQi4qS7s8","execution":{"iopub.status.busy":"2021-11-22T16:39:55.650331Z","iopub.execute_input":"2021-11-22T16:39:55.65103Z","iopub.status.idle":"2021-11-22T16:39:55.655769Z","shell.execute_reply.started":"2021-11-22T16:39:55.650994Z","shell.execute_reply":"2021-11-22T16:39:55.654822Z"},"trusted":true},"source":["labels = ['Apple',              # 0\n","          'Blueberry',          # 1\n","          \"Cherry\",             # 2\n","          \"Corn\",               # 3\n","          \"Grape\",              # 4\n","          \"Orange\",             # 5\n","          \"Peach\",              # 6\n","          \"Pepper\",             # 7\n","          \"Potato\",             # 8\n","          \"Raspberry\",          # 9\n","          \"Soybean\",            # 10\n","          \"Squash\",             # 11\n","          \"Strawberry\",         # 12\n","          \"Tomato\"]             # 13\n","\n","number_of_classes = 14"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aEyrKvOvURnH","execution":{"iopub.status.busy":"2021-11-22T16:39:59.680187Z","iopub.execute_input":"2021-11-22T16:39:59.680462Z","iopub.status.idle":"2021-11-22T16:39:59.68598Z","shell.execute_reply.started":"2021-11-22T16:39:59.680431Z","shell.execute_reply":"2021-11-22T16:39:59.685029Z"},"trusted":true},"source":["input_shape = (256, 256, 3) #3 channel of RGB #256x256 the size \n","image_width = 256\n","image_height = 256\n","\n","epochs = 250 \n","patience_epochs = 30 \n","batch_size = 128 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hv-n9hprUSUy"},"source":["# Data Augmentation"]},{"cell_type":"code","metadata":{"id":"MCCn6uWE1_17","execution":{"iopub.status.busy":"2021-11-22T16:40:37.9905Z","iopub.execute_input":"2021-11-22T16:40:37.990769Z","iopub.status.idle":"2021-11-22T16:40:38.958695Z","shell.execute_reply.started":"2021-11-22T16:40:37.990738Z","shell.execute_reply":"2021-11-22T16:40:38.95797Z"},"trusted":true},"source":["#Here we set the generators for the data augmentation process\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_data_gen = ImageDataGenerator(rotation_range=145,\n","                                        height_shift_range=80, \n","                                        width_shift_range=80,\n","                                        zoom_range=0.5,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True, \n","                                        fill_mode='constant', #if necessary we fill with black pixels\n","                                        cval=0.0,\n","                                        brightness_range=[0.5,1.5], #1.0 denotes the image at the original brightness level\n","                                        shear_range=0.3,    \n","                                        rescale=1/255.) \n","                                        \n","train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=labels, \n","                                               class_mode='categorical',\n","                                               batch_size=batch_size, \n","                                               shuffle=True,\n","                                               seed=seed)\n","\n","valid_data_gen = ImageDataGenerator(rescale=1/255.)\n","valid_gen = train_data_gen.flow_from_directory(directory=validation_dir,\n","                                               target_size=(256,256),\n","                                               color_mode='rgb',\n","                                               classes=labels, \n","                                               class_mode='categorical',\n","                                               batch_size=batch_size,\n","                                               shuffle=False,\n","                                               seed=seed)\n","\n","test_data_gen = ImageDataGenerator(rescale=1/255.)\n","test_gen = train_data_gen.flow_from_directory(directory=test_dir,\n","                                              target_size=(256,256),\n","                                              color_mode='rgb',\n","                                              classes=labels, \n","                                              class_mode='categorical',\n","                                              batch_size=batch_size,\n","                                              shuffle=False,\n","                                              seed=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RuOT9IIfWWeM"},"source":["# Model Configuration"]},{"cell_type":"code","metadata":{"id":"O7f-fDax4Y5N","execution":{"iopub.status.busy":"2021-11-22T16:42:15.848911Z","iopub.execute_input":"2021-11-22T16:42:15.849391Z","iopub.status.idle":"2021-11-22T16:42:15.875545Z","shell.execute_reply.started":"2021-11-22T16:42:15.84933Z","shell.execute_reply":"2021-11-22T16:42:15.874754Z"},"trusted":true},"source":["def build_model(input_shape):\n","\n","    #Build the neural network layer by layer\n","    #input  shape 256x256\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","\n","\n","    #block n.1 (conv + batch + maxPooling)\n","    conv1 = tfkl.Conv2D(\n","        filters=32,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same', #no reduction of the dimensions of the image\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(input_layer)  \n","    \n","    conv1 = tfkl.BatchNormalization(axis=-1, scale=False, name='norm1')(conv1)\n","    conv1 = tfkl.Activation('relu')(conv1)\n","    \n","    pool1 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv1)\n","\n","    #block n.2 (conv + batch + maxPooling)\n","    conv2 = tfkl.Conv2D(\n","        filters=64,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool1) \n","    \n","    conv2 = tfkl.BatchNormalization(axis=-1, scale=False, name='norm2')(conv2)\n","    conv2 = tfkl.Activation('relu')(conv2)\n","    \n","    pool2 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv2)\n","\n","    #block n.3 (conv + batch + maxPooling)\n","    conv3 = tfkl.Conv2D(\n","        filters=128,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool2) \n","    \n","    conv3 = tfkl.BatchNormalization(axis=-1, scale=False, name='norm3')(conv3)\n","    conv3 = tfkl.Activation('relu')(conv3)\n","    \n","    \n","    pool3 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv3)\n","\n","    #block n.4 (conv + batch + maxPooling)\n","    conv4 = tfkl.Conv2D(\n","        filters=256,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool3)  \n","    \n","    conv4 = tfkl.BatchNormalization(axis=-1, scale=False, name='norm4')(conv4)\n","    conv4 = tfkl.Activation('relu')(conv4)\n","    \n","    pool4 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv4)\n","\n","    #block n.5 (conv + batch + maxPooling)\n","    conv5 = tfkl.Conv2D(\n","        filters=512,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool4) \n","    \n","    conv5 = tfkl.BatchNormalization(axis=-1, scale=False, name='norm5')(conv5)\n","    conv5 = tfkl.Activation('relu')(conv5)\n","    \n","    pool5 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv5)\n","    \n","    #block n.6 (conv + batch + maxPooling)\n","    conv6 = tfkl.Conv2D(\n","        filters=1024,\n","        kernel_size=(3, 3),\n","        strides = (1, 1),\n","        padding = 'same',\n","        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n","    )(pool5)\n","    \n","    conv6 = tfkl.BatchNormalization(axis=-1, scale=False, name='norm6')(conv6)\n","    conv6 = tfkl.Activation('relu')(conv6)\n","    \n","    pool6 = tfkl.MaxPooling2D(\n","        pool_size = (2, 2)\n","    )(conv6)\n","\n","    \n","    glob_pooling = tfkl.GlobalAveragePooling2D(name='GloablPooling')(pool6)\n","    \n","    #Fully connected network\n","    classifier_layer1 = tfkl.Dense(units=1024, name='Classifier1', kernel_initializer=tfk.initializers.GlorotUniform(seed), kernel_regularizer=tf.keras.regularizers.l2(2e-6), activation='relu')(glob_pooling)\n","    classifier_layer2 = tfkl.Dense(units=512, name='Classifier2', kernel_initializer=tfk.initializers.GlorotUniform(seed), kernel_regularizer=tf.keras.regularizers.l2(2e-6), activation='relu')(classifier_layer1)\n","    classifier_layer2 = tfkl.Dropout(0.6, seed=seed)(classifier_layer2)\n","    classifier_layer3 = tfkl.Dense(units=256, name='Classifier3', kernel_initializer=tfk.initializers.GlorotUniform(seed), kernel_regularizer=tf.keras.regularizers.l2(2e-6), activation='relu')(classifier_layer2)\n","    classifier_layer3 = tfkl.Dropout(0.5, seed=seed)(classifier_layer3)\n","    classifier_layer4 = tfkl.Dense(units=64, name='Classifier4', kernel_initializer=tfk.initializers.GlorotUniform(seed), kernel_regularizer=tf.keras.regularizers.l2(2e-6), activation='relu')(classifier_layer3)\n","    \n","    #Output layer characterized by the softmax activation function\n","    output_layer = tfkl.Dense(units=number_of_classes, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), kernel_regularizer=tf.keras.regularizers.l2(2e-6), name='Output')(classifier_layer4)\n","    \n","    #Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n","    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n","\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"di4gAAywW-ee","execution":{"iopub.status.busy":"2021-11-22T16:42:20.165348Z","iopub.execute_input":"2021-11-22T16:42:20.165965Z","iopub.status.idle":"2021-11-22T16:42:20.351802Z","shell.execute_reply.started":"2021-11-22T16:42:20.165926Z","shell.execute_reply":"2021-11-22T16:42:20.351113Z"},"trusted":true},"source":["model = build_model(input_shape) \n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lb0t-ebIjae","execution":{"iopub.status.busy":"2021-11-22T16:42:23.915292Z","iopub.execute_input":"2021-11-22T16:42:23.915575Z","iopub.status.idle":"2021-11-22T16:42:23.925093Z","shell.execute_reply.started":"2021-11-22T16:42:23.915544Z","shell.execute_reply":"2021-11-22T16:42:23.924422Z"},"trusted":true},"source":["# Utility function to create folders and callbacks for training\n","from datetime import datetime\n","\n","def create_folders_and_callbacks(model_name):\n","\n","  exps_dir = os.path.join('data_augmentation_experiments')\n","  if not os.path.exists(exps_dir):\n","      os.makedirs(exps_dir)\n","\n","  now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","  if not os.path.exists(exp_dir):\n","      os.makedirs(exp_dir)\n","      \n","  callbacks = []\n","\n","  # Model checkpoint\n","  # ----------------\n","  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","  if not os.path.exists(ckpt_dir):\n","      os.makedirs(ckpt_dir)\n","\n","  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n","                                                     save_weights_only=False, \n","                                                     save_best_only=True, #saves only the best evaluating the val_accuracy\n","                                                     monitor='val_accuracy',\n","                                                     mode='max')  \n","  callbacks.append(ckpt_callback)\n","\n","  # Visualize Learning on Tensorboard\n","  # ---------------------------------\n","  tb_dir = os.path.join(exp_dir, 'tb_logs')\n","  if not os.path.exists(tb_dir):\n","      os.makedirs(tb_dir)\n","      \n","  # By default shows losses and metrics for both training and validation\n","  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n","                                               profile_batch=0,\n","                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n","  callbacks.append(tb_callback)\n","\n","  # Early Stopping\n","  # -------------- #patience epochs settato da noi \n","  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience_epochs, restore_best_weights=True)\n","  callbacks.append(es_callback)\n","\n","  return callbacks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H1osgoJ0cTYR"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"Ce7h4N2dcVk7","execution":{"iopub.status.busy":"2021-11-22T16:42:28.612845Z","iopub.execute_input":"2021-11-22T16:42:28.614548Z","iopub.status.idle":"2021-11-22T16:43:13.108032Z","shell.execute_reply.started":"2021-11-22T16:42:28.614497Z","shell.execute_reply":"2021-11-22T16:43:13.10571Z"},"trusted":true},"source":["tf.get_logger().setLevel('WARNING') #  if you want to suppress only INFOs\n","tf.get_logger().setLevel('ERROR') #  if you want to suppress both WARNINGs and INFOs\n","\n","# Create folders and callbacks and fit\n","aug_callbacks = create_folders_and_callbacks(model_name='CNN')\n","\n","# Train the model\n","history = model.fit(\n","    x = train_gen,\n","    epochs = epochs,\n","    validation_data = valid_gen,\n","    callbacks = aug_callbacks,\n",").history\n","\n","model.save(\"ModelDataAug\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DQHGDS-kcrfW"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"5ntGuHMqcjdu"},"source":["model_aug = tfk.models.load_model('ModelDataAug')\n","model_metrics = model_aug.evaluate(test_gen, return_dict = True)\n","print(model_metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SFZ-lu7QdMUo"},"source":["#Graphs"]},{"cell_type":"code","metadata":{"id":"87R2n8nUdSvd"},"source":["plt.figure(figsize=(15,5))\n","plt.plot(history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n","plt.plot(history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n","plt.ylim(0, 0.1)\n","plt.title('val_loss and train_loss')\n","plt.legend(loc='upper right')\n","plt.grid(alpha=.3)\n","plt.show()"],"execution_count":null,"outputs":[]}]}